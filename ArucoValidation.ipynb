{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ArucoValidation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Zilch123/Aruco-3D-position-Validation/blob/main/ArucoValidation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhMbpWS_xkna"
      },
      "source": [
        "# Author1: Timoth Dev \n",
        "# Author2: Arjun Ram \n",
        "# GNU 3.0 Licence "
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzfJV5elO7of",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4ec6374-f99f-429e-e278-40674129af21"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lL0LV0VNT5H"
      },
      "source": [
        "# !pip install opencv-contrib-python\n",
        "# !git clone https://github.com/ddelago/Aruco-Marker-Calibration-and-Pose-Estimation.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWT1IJ7uP7xu"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import pickle\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2.aruco as aruco\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import savgol_filter\n",
        "from scipy import stats\n",
        "\n",
        "plt.rcParams[\"figure.figsize\"] = (10,5)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ty-xVLusKKMW"
      },
      "source": [
        "Type in your drive path to Data, path is the same till MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9Tp9dCIPGZ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c1c84d3-25ed-40ed-c4ae-c715d14440f9"
      },
      "source": [
        "cd drive/MyDrive/Aruco\\ CMC\\ project/Data/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/.shortcut-targets-by-id/1bOHe3Wct63zxzPGjAqK-HttE3BVPIieY/Data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVZFjd6DCCVb",
        "outputId": "c44675ad-e108-4864-efaf-2f47ae54e230"
      },
      "source": [
        "ls Subject\\ 1/Subject\\ 1/Sub\\ 1\\ SB"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "color.pickle  subject1.avi              subject1_color.avi  subject1_depth.avi\n",
            "prm.pickle    subject1_color_aruco.avi  subject1_color.mp4  xyz.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE0-MXi8Ksrj"
      },
      "source": [
        "def read_calib(RotMatrix):\n",
        "    return np.matrix(RotMatrix[0]), np.matrix(RotMatrix[1])\n",
        "\n",
        "\n",
        "def kinect2table(orig,R_T,kinect_joint):\n",
        "    Local_co = [np.matmul(R_T.T,(x-orig).T) for x in kinect_joint]\n",
        "    return(np.array(Local_co).squeeze())\n",
        "\n",
        "\n",
        "def my_filter(x):\n",
        "    return savgol_filter(x, 3, 1)\n"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yC6SAJAdP6qV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "835d551e-530e-41ff-d61e-f0ec4ba5deb5"
      },
      "source": [
        "with open(\"rotMat_new.pickle\",'rb') as f:\n",
        "    RotMatrix = []\n",
        "    while True:\n",
        "        try:\n",
        "            RotMatrix.append(pickle.load(f))\n",
        "            \n",
        "        except EOFError:\n",
        "            print(RotMatrix[1])\n",
        "            RotMatrix[1][[0, 2]] = -RotMatrix[1][[2, 0]]\n",
        "            RotMatrix[1][1] = - RotMatrix[1][1]\n",
        "            break"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.99871538 -0.02327689 -0.023868  ]\n",
            " [-0.00993747 -0.95835113 -0.27631295]\n",
            " [ 0.04968733  0.27619518 -0.96077129]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V58bhAXWl-Xy",
        "outputId": "7f50ab5d-7b90-4db2-ac01-7879deb3aca3"
      },
      "source": [
        "RotMatrix[1]"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.04968733, -0.27619518,  0.96077129],\n",
              "       [ 0.00993747,  0.95835113,  0.27631295],\n",
              "       [-0.99871538,  0.02327689,  0.023868  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkoCk7HJ9g7v"
      },
      "source": [
        "orig, R_T = read_calib(RotMatrix)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZMPMu1I1P6V",
        "outputId": "bb77dbbe-c358-4703-b923-a45569e3eb27"
      },
      "source": [
        "print(orig,'\\n\\n', R_T)"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-0.141 -0.251  1.404]] \n",
            "\n",
            " [[-0.04968733 -0.27619518  0.96077129]\n",
            " [ 0.00993747  0.95835113  0.27631295]\n",
            " [-0.99871538  0.02327689  0.023868  ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPxOklpm8pqT",
        "outputId": "a98a4a65-c4d3-448a-bbd9-930d3a9698bf"
      },
      "source": [
        "# https://github.com/ddelago/Aruco-Marker-Calibration-and-Pose-Estimation\n",
        "# Load the Github camera calib profile \n",
        "f = open(\"Aruco-Marker-Calibration-and-Pose-Estimation/calibration/CameraCalibration.pckl\", 'rb')\n",
        "(cameraMatrix, distCoeffs, _, _) = pickle.load(f, encoding='latin1')\n",
        "f.close()\n",
        "\n",
        "# Kinect Calib data\n",
        "# https://github.com/shanilfernando/VRInteraction/blob/master/calibration/rgb_calibration.yaml\n",
        "# cameraMatrix = np.array([[ 1.0327407219495085e+03, 0., 9.5685930301206076e+02],\n",
        "#                          [ 0., 1.0323427647512485e+03, 5.3914133979587950e+02],\n",
        "#                          [0., 0., 1. ]])\n",
        "# distCoeffs=np.array([[ 2.0429028189430772e-02, -7.8399448855923665e-03, \n",
        "#                      -3.0949667668667908e-03, 2.1848647826377197e-03, -5.2344198896187882e-02 ]])\n",
        "\n",
        "print(cameraMatrix, distCoeffs )\n"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.44095165e+03 0.00000000e+00 9.40438869e+02]\n",
            " [0.00000000e+00 1.43677267e+03 5.27992515e+02]\n",
            " [0.00000000e+00 0.00000000e+00 1.00000000e+00]] [[ 0.07833557 -0.51920323 -0.00682128 -0.00380227  1.04236729]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDgSJO47QXKm"
      },
      "source": [
        "\n",
        "# Constant parameters used in Aruco methods\n",
        "ARUCO_PARAMETERS = aruco.DetectorParameters_create()\n",
        "ARUCO_DICT = aruco.Dictionary_get(aruco.DICT_5X5_50)\n",
        "\n",
        "# Create grid board object we're using in our video\n",
        "board = aruco.GridBoard_create(\n",
        "        markersX=1,\n",
        "        markersY=1,\n",
        "        markerLength=64,\n",
        "        markerSeparation=0.01,\n",
        "        dictionary=ARUCO_DICT)\n",
        "\n",
        "# Create vectors we'll be using for rotations and translations for postures\n",
        "rotation_vectors, translation_vectors = None, None\n",
        "\n",
        "#axis is just for visualisation of coordinate frame \n",
        "axis = np.float32([[-.5,-.5,0], [-.5,.5,0], [.5,.5,0], [.5,-.5,0],\n",
        "                   [-.5,-.5,1],[-.5,.5,1],[.5,.5,1],[.5,-.5,1] ])\n",
        "\n",
        "# https://stackoverflow.com/questions/46363618/aruco-markers-with-opencv-get-the-3d-corner-coordinates?rq=1\n",
        "def rotate_marker_corners(rvec, markersize, tvec = None):\n",
        "\n",
        "    mhalf = markersize / 2.0\n",
        "\n",
        "    # convert rot vector to rot matrix both do: markerworld -> cam-world\n",
        "    mrv, jacobian = cv2.Rodrigues(rvec)\n",
        "\n",
        "    #in markerworld the corners are all in the xy-plane so z is zero at first\n",
        "    X = mhalf * mrv[:,0] #rotate the x = mhalf\n",
        "    Y = mhalf * mrv[:,1] #rotate the y = mhalf\n",
        "    minusX = X * (-1)\n",
        "    minusY = Y * (-1)\n",
        "\n",
        "    # calculate 4 corners of the marker in camworld. corners are enumerated clockwise\n",
        "    markercorners = []\n",
        "    markercorners.append(np.add(minusX, Y)) #was upper left in markerworld\n",
        "    markercorners.append(np.add(X, Y)) #was upper right in markerworld\n",
        "    markercorners.append(np.add( X, minusY)) #was lower right in markerworld\n",
        "    markercorners.append(np.add(minusX, minusY)) #was lower left in markerworld\n",
        "    # if tvec given, move all by tvec\n",
        "    if tvec is not None:\n",
        "        C = tvec #center of marker in camworld\n",
        "        for i, mc in enumerate(markercorners):\n",
        "            markercorners[i] = np.add(C,mc) #add tvec to each corner\n",
        "    #print('Vec X, Y, C, dot(X,Y)', X,Y,C, np.dot(X,Y)) # just for debug\n",
        "    markercorners = np.array(markercorners,dtype=np.float32) # type needed when used as input to cv2\n",
        "    return markercorners, mrv"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyytdzhWRl18"
      },
      "source": [
        "end_video_no =2\n",
        "kinect_df = {}\n",
        "for subject_number in range(1,end_video_no):\n",
        "  kinect_df_ =pd.DataFrame(columns=['time_raw','kx', 'ky', 'kz', 'ax', 'ay', 'az' ])\n",
        "  (height, width, layers) = (368,432,3)\n",
        "  fps=14.97\n",
        "  fourcc = cv2.VideoWriter_fourcc(*'MP42')\n",
        "  video = cv2.VideoWriter(\"Subject \"+str(subject_number)+\"/Subject \"+str(subject_number)+\n",
        "                          \"/Sub \"+str(subject_number)+\" SB/subject\"+str(subject_number)+\"_color_aruco.avi\", fourcc, float(fps), (width, height))\n",
        "  # video = cv2.VideoWriter(\"'drive'/'MyDrive'/'Aruco CMC project'/'subject1.mp4'\", fourcc, float(fps), (width, height))\n",
        "  i=0\n",
        "  with open(\"Subject \"+str(subject_number)+\"/Subject \"+str(subject_number)+\"/Sub \"+str(subject_number)+\" SB/color.pickle\",'rb') as color_img, \\\n",
        "       open(\"Subject \"+str(subject_number)+\"/Subject \"+str(subject_number)+\"/Sub \"+str(subject_number)+\" SB/xyz.pickle\",'rb') as depth_img, \\\n",
        "       open(\"Subject \"+str(subject_number)+\"/Subject \"+str(subject_number)+\"/Sub \"+str(subject_number)+\" SB/prm.pickle\",'rb') as prm:\n",
        "      while True:\n",
        "          try:\n",
        "            # Change RGB to BGR\n",
        "            color_image = pickle.load(color_img)\n",
        "            Depth_xyz = pickle.load(depth_img)\n",
        "            gray = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Detect Aruco markers\n",
        "            corners, ids, rejectedImgPoints = aruco.detectMarkers(gray, ARUCO_DICT, parameters=ARUCO_PARAMETERS)\n",
        "            # Refine detected markers\n",
        "            # Eliminates markers not part of our board, adds missing markers to the board\n",
        "            corners, ids, rejectedImgPoints, recoveredIds = aruco.refineDetectedMarkers(\n",
        "                image = gray,\n",
        "                board = board,\n",
        "                detectedCorners = corners,\n",
        "                detectedIds = ids,\n",
        "                rejectedCorners = rejectedImgPoints,\n",
        "                cameraMatrix = cameraMatrix,\n",
        "                distCoeffs = distCoeffs)   \n",
        "            ProjectImage = aruco.drawDetectedMarkers(color_image, corners, borderColor=(0, 0, 255))\n",
        "            if ids is not None and len(ids) > 0:\n",
        "              # Estimate the posture per each Aruco marker\n",
        "              rotation_vectors, translation_vectors, _objPoints = aruco.estimatePoseSingleMarkers(corners, 1, cameraMatrix, distCoeffs)\n",
        "\n",
        "              markerCorner = np.array((corners)).reshape((4, 2))\n",
        "              (topLeft, topRight, bottomRight, bottomLeft) = markerCorner\n",
        "\n",
        "              # convert each of the (x, y)-coordinate pairs to integers\n",
        "              topRight = (int(topRight[0]), int(topRight[1]))\n",
        "              bottomRight = (int(bottomRight[0]), int(bottomRight[1]))\n",
        "              bottomLeft = (int(bottomLeft[0]), int(bottomLeft[1]))\n",
        "              topLeft = (int(topLeft[0]), int(topLeft[1]))\n",
        "\n",
        "              # draw the bounding box of the ArUCo detection\n",
        "              cv2.line(ProjectImage, topLeft, topRight, (0, 255, 0), 2)\n",
        "              cv2.line(ProjectImage, topRight, bottomRight, (0, 255, 0), 2)\n",
        "              cv2.line(ProjectImage, bottomRight, bottomLeft, (0, 255, 0), 2)\n",
        "              cv2.line(ProjectImage, bottomLeft, topLeft, (0, 255, 0), 2)\n",
        "\n",
        "              # compute and draw the center (x, y)-coordinates of the\n",
        "              # ArUco marker\n",
        "              cX = int((topLeft[0] + bottomRight[0]) / 2.0)\n",
        "              cY = int((topLeft[1] + bottomRight[1]) / 2.0)\n",
        "              cv2.circle(ProjectImage, (cX, cY), 4, (0, 0, 255), -1)\n",
        "\n",
        "              # 3D Aruco Coordinates \n",
        "              # markercorners_3d, mrv = rotate_marker_corners(rotation_vectors, markersize = 64, tvec = translation_vectors)\n",
        "              \n",
        "              # markerCorner_xyz = np.array((markercorners_3d)).reshape((4, 3))\n",
        "              # (topLeft, topRight, bottomRight, bottomLeft) = markerCorner_xyz\n",
        "\n",
        "              # # convert each of the (x, y)-coordinate pairs to integers\n",
        "              # topRight = (topRight[0], topRight[1], topRight[2])\n",
        "              # bottomRight = (bottomRight[0], bottomRight[1], bottomRight[2])\n",
        "              # bottomLeft = (bottomLeft[0], bottomLeft[1], bottomLeft[2])\n",
        "              # topLeft = (topLeft[0], topLeft[1], topLeft[2])\n",
        "              \n",
        "              # # compute  the center (x, y, z)-coordinates of the\n",
        "              # # ArUco marker\n",
        "              # cX_3d = (topLeft[0] + bottomRight[0]) / 2.0\n",
        "              # cY_3d = (topLeft[1] + bottomRight[1]) / 2.0\n",
        "              # cZ_3d = (topLeft[2] + bottomRight[2]) / 2.0\n",
        "              \n",
        "              kinectxyz = np.append(pd.to_datetime(pickle.load(prm)), kinect2table(orig,R_T,np.array([Depth_xyz[cY][cX]])))\n",
        "              # kxyz_axyz = np.append(kinectxyz, np.array([cX_3d, cY_3d, cZ_3d]))\n",
        "              # print(\"Depth raw \", (Depth_xyz[cY][cX]))\n",
        "              # print(\"tras vec \", translation_vectors)\n",
        "              # print(\"k data \", kinect2table(orig,R_T,np.array([Depth_xyz[cY][cX]])))\n",
        " \n",
        "              kxyz_axyz = np.append(kinectxyz, kinect2table(orig,R_T,translation_vectors))\n",
        "              kinect_df_.loc[len(kinect_df_)] = kxyz_axyz\n",
        "\n",
        "              # print(\"mark \", markercorners_)\n",
        "              # print(\"\\n  \", mrv)\n",
        "            #   for rvec, tvec in zip(rotation_vectors, translation_vectors):\n",
        "            #       if len(sys.argv) == 2 and sys.argv[1] == 'cube':\n",
        "            #           try:\n",
        "            #               imgpts, jac = cv2.projectPoints(axis, rvec, tvec, cameraMatrix, distCoeffs)\n",
        "            #               # ProjectImage = drawCube(ProjectImage, corners, imgpts)\n",
        "            #           except:\n",
        "            #               continue\n",
        "            #       else:    \n",
        "            #         pass\n",
        "            #           # ProjectImage = aruco.drawAxis(ProjectImage, cameraMatrix, distCoeffs, rvec, tvec, 1)\n",
        "            # # cv2.imshow('ProjectImage', ProjectImage)\n",
        "\n",
        "            # video.write(cv2.cvtColor(ProjectImage, cv2.COLOR_RGB2BGR))\n",
        "            i = i+1\n",
        "          except EOFError:\n",
        "            kinect_df_['time'] = (kinect_df_['time_raw'] -kinect_df_['time_raw'][0]).dt.total_seconds()\n",
        "            kinect_df[subject_number] = kinect_df_\n",
        "            break\n",
        "  # video.release()\n",
        "  # !ffmpeg -y -loglevel info -i subject3_color.avi subject3_color.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Hb9mOVZrEl"
      },
      "source": [
        "kinect_df[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTdciwdkKTRu"
      },
      "source": [
        "#Get kinect and mocap data \n",
        "# Get the time delay between Kinect and Mocap \n",
        "# Trunkate the data\n",
        "Time_delay={}\n",
        "df_mocap={}\n",
        "kinect_mocap = {}\n",
        "for video_no in range(1,2):\n",
        "  with open(\"Subject \"+str(video_no)+\"/Subject \"+str(video_no)+\"/Sub \"+str(video_no)+\" MC.csv\") as Mocap_data:\n",
        "\n",
        "      df_mocap[video_no] = pd.read_csv(Mocap_data)\n",
        "      opti_time = datetime.strptime(df_mocap[video_no].columns[11], '%Y-%m-%d %I.%M.%S.%f %p')\n",
        " \n",
        "      kinect_time = kinect_df[video_no]['time_raw'][0]\n",
        "\n",
        "      print(\"Kinect Start\", kinect_time,\" Opti Start\",opti_time)\n",
        "      Time_delay[video_no] = (kinect_time-opti_time).total_seconds()\n",
        "      print(Time_delay[video_no])\n",
        "      \n",
        "      df_mocap[video_no].columns = df_mocap[video_no].iloc[4][:2].append(df_mocap[video_no].loc[1][2:].str.replace(r':', '_') + df_mocap[video_no].loc[4][2:])\n",
        "      df_mocap[video_no] = df_mocap[video_no].iloc[5:].dropna(axis=1, how='all')\n",
        "      df_mocap[video_no] = df_mocap[video_no].reset_index(drop=True)\n",
        "      df_mocap[video_no] = df_mocap[video_no].astype(np.float64)\n",
        "      df_mocap[video_no]['time_matched'] = round(df_mocap[video_no]['Time (Seconds)'] - round(Time_delay[video_no],2),2)\n",
        "      \n",
        "      kinect_mocap[video_no] = kinect_df[video_no].copy()\n",
        "      kinect_mocap[video_no]['kx'] = kinect_mocap[video_no]['kx'].astype(int)\n",
        "      kinect_mocap[video_no]['ky'] = kinect_mocap[video_no]['ky'].astype(int)\n",
        "      kinect_mocap[video_no]['kz'] = kinect_mocap[video_no]['kz'].astype(int)\n",
        "      kinect_mocap[video_no]['time_matched'] = round(kinect_mocap[video_no]['time'],2)\n",
        "    \n",
        "      kinect_mocap[video_no] = kinect_mocap[video_no].merge(df_mocap[video_no], how='left', on='time_matched')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v3dj6lZFrIyg"
      },
      "source": [
        "kinect_mocap[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TBKiVd4agUC"
      },
      "source": [
        "kinect_mocap[11] = kinect_mocap[1] - kinect_mocap[1].loc[0].values.squeeze()\n",
        "\n",
        "# savgol filter\n",
        "kinect_mocap[11] = kinect_mocap[11].apply(my_filter)\n",
        "# Outlier Removal\n",
        "kinect_mocap[11] = kinect_mocap[11][(np.abs(stats.zscore(kinect_mocap[11])) < 3).all(axis=1)]\n",
        "\n",
        "\n",
        "# kinect_mocap[22] = kinect_mocap[2] - kinect_mocap[2].loc[0].values.squeeze()\n",
        "# # savgol filter\n",
        "# kinect_mocap[22] = kinect_mocap[22].apply(my_filter)\n",
        "# # Outlier Removal\n",
        "# kinect_mocap[22] = kinect_mocap[22][(np.abs(stats.zscore(kinect_mocap[22])) < 3).all(axis=1)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtCiGIQypLeZ"
      },
      "source": [
        "fig, ax = plt.subplots(3,3)\n",
        "# Note that ax is now an array consisting of the individual axis\n",
        "plt.xlabel('fps')\n",
        "plt.ylabel('distance')\n",
        "\n",
        "ax[0,0].plot(kinect_mocap[11]['ax'])\n",
        "ax[0,0].set_title('ax')\n",
        "ax[0,0].set_xlabel('fps')\n",
        "ax[0,0].set_ylabel('distance')\n",
        "\n",
        "ax[0,1].plot(kinect_mocap[11]['ay'])\n",
        "ax[0,1].set_title('ay')\n",
        "ax[0,1].set_xlabel('fps')\n",
        "ax[0,1].set_ylabel('distance')\n",
        "\n",
        "ax[0,2].plot(kinect_mocap[11]['az'])\n",
        "ax[0,2].set_title('az')\n",
        "ax[0,2].set_xlabel('fps')\n",
        "ax[0,2].set_ylabel('distance')\n",
        "\n",
        "ax[1,0].plot(kinect_mocap[11]['Skateboard_LX'])\n",
        "ax[1,0].set_title('LX')\n",
        "ax[1,0].set_xlabel('fps')\n",
        "ax[1,0].set_ylabel('distance')\n",
        "\n",
        "ax[1,1].plot(kinect_mocap[11]['Skateboard_LY'])\n",
        "ax[1,1].set_title('LY')\n",
        "ax[1,1].set_xlabel('fps')\n",
        "ax[1,1].set_ylabel('distance')\n",
        "\n",
        "ax[1,2].plot(kinect_mocap[11]['Skateboard_LZ'])\n",
        "ax[1,2].set_title('LZ')\n",
        "ax[1,2].set_xlabel('fps')\n",
        "ax[1,2].set_ylabel('distance')\n",
        "\n",
        "ax[2,0].plot(kinect_mocap[11]['kx'])\n",
        "ax[2,0].set_title('KX')\n",
        "ax[2,0].set_xlabel('fps')\n",
        "ax[2,0].set_ylabel('distance')\n",
        "\n",
        "ax[2,1].plot(kinect_mocap[11]['ky'])\n",
        "ax[2,1].set_title('KY')\n",
        "ax[2,1].set_xlabel('fps')\n",
        "ax[2,1].set_ylabel('distance')\n",
        "\n",
        "ax[2,2].plot(kinect_mocap[11]['kz'])\n",
        "ax[2,2].set_title('KZ')\n",
        "ax[2,2].set_xlabel('fps')\n",
        "ax[2,2].set_ylabel('distance')\n",
        "\n",
        "\n",
        "\n",
        "plt.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2LrJx5CWMTDt"
      },
      "source": [
        ""
      ],
      "execution_count": 162,
      "outputs": []
    }
  ]
}